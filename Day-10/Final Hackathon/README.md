# ğŸ¤ Agentic AI-Based Voice-Based Site Customizer

**ğŸ“Œ Project Title:** Agentic AI-Based Voice-Based Site Customizer  
**ğŸ‘¤ Participant:** Nithish Kumar S L (PF-2)  
**ğŸ† Event:** Agentic AI Workshop - Final Hackathon Project

---

## ğŸ§  Project Overview

The **Agentic AI-Based Voice-Based Site Customizer** is a revolutionary multi-agent, LLM-powered system that enables users to create and customize websites through natural voice commands. This intelligent platform leverages advanced AI agents working in harmony to transform spoken instructions into dynamic website modifications in real-time.

### âœ¨ Key Features
- ğŸ™ï¸ **Voice-First Interface** - Natural speech-to-website generation
- ğŸ¤– **Multi-Agent Architecture** - 5 specialized AI agents working collaboratively
- ğŸ”„ **Real-Time Updates** - Instant website modifications and live preview
- ğŸ§  **RAG-Enhanced Intelligence** - Context-aware design suggestions
- ğŸ¨ **Professional UI** - Modern chatbot-style interface with IDE-like controls
- ğŸ’¾ **Session Management** - Save, load, and manage multiple projects
- ğŸ” **Intelligent Validation** - Ensures design best practices and user intent alignment

---

## ğŸ” Agentic Workflow

Our system employs a sophisticated 5-agent architecture that processes voice commands through a coordinated workflow:

### ğŸ¯ Core Agents Overview

```mermaid
graph TD
    A[ğŸ¤ User Voice Input] --> B[Voice-to-Text Agent]
    B --> C[Semantic Intent Router Agent]
    C --> D[Contextual Editor Agent]
    C --> E[RAG-Enabled Response Agent]
    D --> F[Validation Agent]
    E --> F
    F --> G[ğŸŒ Updated Website]
    
    H[ğŸ“š Knowledge Base] --> E
    I[ğŸ§  Memory Module] --> C
    I --> D
    I --> E
```

### ğŸ” Detailed Agent Descriptions

#### 1. ğŸ™ï¸ Voice-to-Text Agent
**Primary Role:** Speech Recognition & Processing
- Converts user speech into structured text using Web Speech API
- Handles multiple languages and accents
- Filters background noise and normalizes audio input
- Provides real-time transcription with interim results
- **Technology Stack:** Web Speech API, OpenAI Whisper (fallback)

#### 2. ğŸ§­ Semantic Intent Router Agent
**Primary Role:** Intent Analysis & Routing
- Analyzes transcribed voice commands using NLP
- Determines user intent (layout changes, styling, content modifications)
- Routes commands to appropriate specialized agents
- Maintains conversation context and user preferences
- **Technology Stack:** Gemini Pro API, Custom NLP models

#### 3. âœï¸ Contextual Editor Agent
**Primary Role:** Website Modification & Editing
- Executes site layout and component modifications
- Handles text, color, layout, and structural changes
- Maintains HTML/CSS integrity during edits
- Implements responsive design principles
- **Technology Stack:** Gemini Pro API, Custom HTML/CSS processors

#### 4. ğŸ“š RAG-Enabled Response Agent
**Primary Role:** Knowledge Retrieval & Enhancement
- Uses Retrieval-Augmented Generation for design suggestions
- Fetches relevant code snippets from knowledge base
- Provides contextual recommendations and alternatives
- Enhances responses with best practices and examples
- **Technology Stack:** ChromaDB, Vector embeddings, Gemini Pro API

#### 5. âœ… Validation Agent
**Primary Role:** Quality Assurance & Compliance
- Validates final customizations against user intent
- Ensures design best practices and accessibility standards
- Performs code quality checks and optimization
- Provides feedback and suggestions for improvements
- **Technology Stack:** Custom validation rules, Gemini Pro API

---

## ğŸ—ï¸ Agent Design & Communication

### ğŸ›ï¸ Centralized Orchestration
```python
# Agent Coordinator Architecture
class AgentCoordinator:
    def __init__(self):
        self.voice_agent = VoiceToTextAgent()
        self.router_agent = SemanticIntentRouter()
        self.editor_agent = ContextualEditor()
        self.rag_agent = RAGEnabledResponse()
        self.validator_agent = ValidationAgent()
        self.memory = SessionMemoryModule()
    
    async def process_voice_command(self, audio_input):
        # Orchestrated workflow
        text = await self.voice_agent.transcribe(audio_input)
        intent = await self.router_agent.analyze(text, self.memory)
        modifications = await self.editor_agent.edit(intent)
        enhanced_response = await self.rag_agent.enhance(modifications)
        validated_result = await self.validator_agent.validate(enhanced_response)
        return validated_result
```

### ğŸ§  Memory & Context Management
- **Session Persistence:** Maintains user preferences and conversation history
- **Context Windows:** Preserves recent interactions for coherent responses
- **User Profiling:** Learns from user patterns and preferences
- **Undo/Redo System:** Tracks all modifications for easy reversal

### ğŸ”— API Communication Layer
- **RESTful APIs:** Clean endpoints for each agent's functionality
- **WebSocket Support:** Real-time communication for live updates
- **Event-Driven Architecture:** Asynchronous processing for optimal performance
- **Error Handling:** Comprehensive error recovery and fallback mechanisms

---

## ğŸ’¡ LLMs and Tools Used

### ğŸ¤– Large Language Models

#### **Gemini Pro API**
- **Primary Use:** Design intent interpretation and code generation
- **Capabilities:** Natural language understanding, HTML/CSS generation
- **Integration:** Core reasoning engine for all agents

#### **Web Speech API / OpenAI Whisper**
- **Primary Use:** Speech-to-text processing
- **Capabilities:** Real-time voice recognition, multiple language support
- **Integration:** Voice input processing with fallback mechanisms

### ğŸ› ï¸ Technology Stack

#### **Frontend (Next.js)**
```typescript
// Key Technologies
- Next.js 14 (React Framework)
- TypeScript (Type Safety)
- Tailwind CSS (Styling)
- Web Speech API (Voice Recognition)
- Custom React Hooks (Voice & Storage)
```

#### **Backend (Python FastAPI)**
```python
# Core Dependencies
- FastAPI (Modern Web Framework)
- LangChain (Agent Orchestration)
- ChromaDB (Vector Database)
- Pydantic (Data Validation)
- Uvicorn (ASGI Server)
```

#### **AI & ML Stack**
- **Vector Database:** ChromaDB for semantic search and RAG
- **Embeddings:** Sentence transformers for text vectorization
- **LLM Integration:** Google Gemini API for natural language processing
- **Agent Framework:** Custom LangChain-based orchestration

---

## ğŸš€ Scalability & Deployment

### ğŸ“ˆ Scalable Architecture
- **Microservices Design:** Each agent can be deployed independently
- **Horizontal Scaling:** Support for multiple concurrent users
- **Load Balancing:** Distributed processing across multiple instances
- **Caching Layer:** Redis for session and response caching

### ğŸ³ Containerization
```dockerfile
# Docker Configuration
FROM python:3.11-slim
WORKDIR /app
COPY requirements.txt .
RUN pip install -r requirements.txt
COPY . .
EXPOSE 8000
CMD ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8000"]
```

### â˜ï¸ Cloud Deployment
- **Frontend:** Vercel/Netlify for static site hosting
- **Backend:** AWS/GCP/Azure for API services
- **Database:** Managed vector database services
- **CDN:** Global content delivery for optimal performance

---

## ğŸ§­ Visual Diagrams

### ğŸ“Š System Architecture Diagram
![Agentic Flow Diagram](./assets/agentic-flow-diagram.png)

### ğŸ”„ Agent Communication Flow
```mermaid
sequenceDiagram
    participant U as User
    participant V as Voice Agent
    participant R as Router Agent
    participant E as Editor Agent
    participant RAG as RAG Agent
    participant Val as Validator
    participant UI as Frontend
    
    U->>V: Voice Command
    V->>R: Transcribed Text
    R->>E: Intent + Context
    R->>RAG: Enhancement Request
    E->>Val: Modified HTML/CSS
    RAG->>Val: Enhanced Response
    Val->>UI: Validated Result
    UI->>U: Updated Website
```

### ğŸ—ï¸ Technical Architecture
![Technical Architecture](./assets/technical-architecture.png)

---

## ğŸ“‚ Repository Structure

```
Day-10/Final Hackathon/
â”œâ”€â”€ ğŸ“ frontend/                    # Next.js Frontend Application
â”‚   â”œâ”€â”€ ğŸ“ src/
â”‚   â”‚   â”œâ”€â”€ ğŸ“ app/                 # Next.js App Router
â”‚   â”‚   â”‚   â”œâ”€â”€ page.tsx            # Home/Generator Page
â”‚   â”‚   â”‚   â”œâ”€â”€ editor/
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ page.tsx        # Website Editor Interface
â”‚   â”‚   â”‚   â”œâ”€â”€ layout.tsx          # Root Layout
â”‚   â”‚   â”‚   â””â”€â”€ globals.css         # Global Styles
â”‚   â”‚   â”œâ”€â”€ ğŸ“ components/          # React Components
â”‚   â”‚   â”‚   â”œâ”€â”€ VoiceButton.tsx     # Voice Recognition Button
â”‚   â”‚   â”‚   â”œâ”€â”€ IntelligentResponse.tsx # AI Response Component
â”‚   â”‚   â”‚   â””â”€â”€ ClientOnly.tsx      # Client-side Only Wrapper
â”‚   â”‚   â”œâ”€â”€ ğŸ“ hooks/               # Custom React Hooks
â”‚   â”‚   â”‚   â”œâ”€â”€ useVoiceRecognition.ts # Voice Recognition Hook
â”‚   â”‚   â”‚   â””â”€â”€ useSessionStorage.ts   # Session Management Hook
â”‚   â”‚   â””â”€â”€ ğŸ“ services/            # API Integration
â”‚   â”‚       â””â”€â”€ api.ts              # Backend API Client
â”‚   â”œâ”€â”€ package.json                # Node.js Dependencies
â”‚   â”œâ”€â”€ next.config.ts              # Next.js Configuration
â”‚   â”œâ”€â”€ tailwind.config.ts          # Tailwind CSS Config
â”‚   â””â”€â”€ .env.local.example          # Environment Variables Template
â”‚
â”œâ”€â”€ ğŸ“ backend/                     # Python FastAPI Backend
â”‚   â”œâ”€â”€ main.py                     # FastAPI Application Entry Point
â”‚   â”œâ”€â”€ ğŸ“ services/                # Business Logic Services
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ website_generator.py    # Website Generation Service
â”‚   â”‚   â”œâ”€â”€ html_editor.py          # HTML/CSS Editing Service
â”‚   â”‚   â”œâ”€â”€ intelligent_response.py # AI Response Processing
â”‚   â”‚   â”œâ”€â”€ session_manager.py      # Session Management
â”‚   â”‚   â”œâ”€â”€ rag_service.py          # RAG Implementation
â”‚   â”‚   â””â”€â”€ vector_store.py         # Vector Database Interface
â”‚   â”œâ”€â”€ ğŸ“ core/                    # Core Configuration
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ config.py               # Application Configuration
â”‚   â”œâ”€â”€ ğŸ“ chroma_db/               # Vector Database Storage
â”‚   â”œâ”€â”€ ğŸ“ user_files/              # Generated Website Files
â”‚   â”œâ”€â”€ requirements.txt            # Python Dependencies
â”‚   â”œâ”€â”€ requirements_simple.txt     # Simplified Dependencies
â”‚   â”œâ”€â”€ .env_example                # Environment Variables Template
â”‚   â””â”€â”€ start_server.py             # Development Server Launcher
â”‚
â”œâ”€â”€ ğŸ“ assets/                      # Documentation Assets
â”‚   â”œâ”€â”€ agentic-flow-diagram.png    # Agent Workflow Diagram
â”‚   â”œâ”€â”€ technical-architecture.png  # System Architecture
â”‚   â””â”€â”€ ui-screenshots/             # Application Screenshots
â”‚
â”œâ”€â”€ .gitignore                      # Git Ignore Rules
â””â”€â”€ README.md                       # This File
```

---

## ğŸš€ How to Run

### ğŸ“‹ Prerequisites
- **Node.js 18+** (for frontend development)
- **Python 3.8+** (for backend services)
- **Gemini API Key** (from Google AI Studio)
- **Modern Browser** (Chrome/Edge recommended for voice features)

### ğŸ› ï¸ Installation Steps

#### 1. Clone Repository
```bash
git clone <repository-url>
cd "Day-10/Final Hackathon"
```

#### 2. Backend Setup
```bash
# Navigate to backend directory
cd backend

# Create virtual environment
python -m venv venv

# Activate virtual environment
# Windows:
venv\Scripts\activate
# macOS/Linux:
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt

# Setup environment variables
cp env_example .env
# Edit .env file and add your GEMINI_API_KEY

# Start the backend server
python start_server.py
```

#### 3. Frontend Setup
```bash
# Navigate to frontend directory (new terminal)
cd frontend

# Install dependencies
npm install

# Setup environment variables
cp env_local_example .env.local
# Edit .env.local if needed

# Start development server
npm run dev

# Or use provided scripts:
# Windows: start.bat
# macOS/Linux: ./start.sh
```

#### 4. Access Application
- **Frontend Interface:** http://localhost:3000
- **Backend API:** http://localhost:8000
- **API Documentation:** http://localhost:8000/docs

---

## ğŸ¯ Usage Examples

### ğŸ™ï¸ Voice Commands Examples

#### Website Generation
```
"Create a modern portfolio website with dark theme"
"Generate a business landing page with contact form"
"Build a photography portfolio with image gallery"
```

#### Style Modifications
```
"Change the header color to blue"
"Make the text bigger and center it"
"Add a gradient background"
"Update the font to something more modern"
```

#### Layout Changes
```
"Add a navigation menu at the top"
"Create a two-column layout"
"Insert a contact form at the bottom"
"Add a hero section with call-to-action button"
```

#### Content Updates
```
"Change the title to 'Welcome to My Site'"
"Add more paragraphs about our services"
"Include social media links in the footer"
"Update the company description"
```

---

## ğŸ› Troubleshooting

### â— Common Issues

#### Voice Recognition Not Working
- Use Chrome or Edge browsers
- Ensure microphone permissions are granted
- Verify HTTPS in production environments

#### API Connection Errors
- Verify backend is running on port 8000
- Check CORS configuration in backend
- Ensure API URL is correct in frontend

#### Gemini API Errors
- Verify API key is correct in .env file
- Check API quota and billing status
- Ensure Gemini API is enabled

#### Dependency Conflicts
```bash
# Use simplified dependencies if needed
pip install -r requirements_simple.txt
```

---

## ğŸ¤ Contributing

### ğŸ’¡ How to Contribute
1. **Fork the repository**
2. **Create a feature branch** (`git checkout -b feature/amazing-feature`)
3. **Commit your changes** (`git commit -m 'Add amazing feature'`)
4. **Push to the branch** (`git push origin feature/amazing-feature`)
5. **Open a Pull Request**

---

## ğŸ“„ License

This project is part of the **Agentic AI Workshop Final Hackathon**. All rights reserved.

### ğŸ† Hackathon Information
- **Event:** Agentic AI Workshop
- **Category:** Final Hackathon Project
- **Participant:** Nithish Kumar S L (PF-2)
- **Submission Date:** 2024

---

## ğŸ“¬ Contact & Support

### ğŸ‘¤ Project Maintainer
**Nithish Kumar S L**
- **Email:** nithish.k.ihub@snsgroups.com
- **Participant ID:** PF-2
- **Institution:** SNS Groups

### ğŸ™ Acknowledgments
- **Agentic AI Workshop** organizers and mentors
- **Google Gemini AI** team for providing advanced language models
- **Open Source Community** for the amazing tools and libraries
- **Fellow Participants** for collaboration and inspiration

---

**ğŸ‰ Ready to revolutionize website creation with voice commands? Start with the installation guide above and begin building your voice-controlled websites today!**

---

*Last Updated: 2024 | Version: 1.0.0 | Hackathon Submission* 
